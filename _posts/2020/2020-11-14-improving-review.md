---
layout: single
title: "[The Gradient] How Can We Improve Peer Review in NLP?"
date: 2020-11-14 19:00:00 +0200
categories: paper
tags: peer-review 
mathjax: false
toc: false
canonical_url: "https://thegradient.pub/how-can-we-improve-peer-review-in-nlp/"
---

This is a post I wrote for The Gradient: [https://thegradient.pub/how-can-we-improve-peer-review-in-nlp/](https://thegradient.pub/how-can-we-improve-peer-review-in-nlp/). 
It reports on a position paper that discusses the heuristics used by reviewers in NLP conferences, and what are the feasible goals for the peer review process.

> Anna Rogers and Isabelle Augenstein. 2020. What Can We Do to Improve Peer Review in NLP?. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1256–1262, Online. Association for Computational Linguistics. [https://aclanthology.org/2020.findings-emnlp.112/](https://aclanthology.org/2020.findings-emnlp.112/)

See also this follow-up study on community preferences for how paper-reviewer matching should be done:

> Terne Thorn Jakobsen and Anna Rogers. 2022. What Factors Should Paper-Reviewer Assignments Rely On? Community Perspectives on Issues and Ideals in Conference Peer-Review. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4810–4823, Seattle, United States. Association for Computational Linguistics. [https://aclanthology.org/2022.naacl-main.354/](https://aclanthology.org/2022.naacl-main.354/)
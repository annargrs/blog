var store = [{
        "title": "Why blog about NLP in 2019?",
        "excerpt":"When I said I wanted to start a research blog, I got asked why - wasn‚Äôt it something from the nineties that nobody did anymore? That‚Äôs actually not an unreasonable question: nobody is even able to keep up with arXiv anymore, why introduce any more sources of long reads? Sure,...","categories": ["squib"],
        "tags": ["academia"],
        "url": "/2019/why-blog/",
        "teaser": null
      },{
        "title": "How the Transformers broke NLP leaderboards",
        "excerpt":"This post summarizes some of the recent XLNet-prompted discussions on Twitter and offline. Idea credits go to Yoav Goldberg, Sam Bowman, Jason Weston, Alexis Conneau, Ted Pedersen, fellow members of Text Machine Lab, and many others. Any misconfiguration of those ideas is my own. A big reason why NLP is...","categories": ["squib"],
        "tags": ["academia","methodology"],
        "url": "/2019/leaderboards/",
        "teaser": null
      },{
        "title": "On word analogies and negative results in NLP",
        "excerpt":"In real world, fake news spread faster than facts. People‚Äôs attention is caught by sensational, exaggerated, clickbait-y messages like ‚Äú5.23 million more immigrants are moving to the UK‚Äù. Any subsequent fact-checking messages look less sensational and they will not reach as many people. Once the damage is done, it‚Äôs done....","categories": ["squib"],
        "tags": ["academia","methodology","negresults","review"],
        "url": "/2019/analogies/",
        "teaser": null
      },{
        "title": "Talking to people outside your echo chamber: SocNLP challenges",
        "excerpt":"This blog is NOT political, even though the story below will show some of my political views. I‚Äôm sharing it because it highlights a burning issue in computational social science that is getting nowhere near enough attention. Reader beware. Academics and Populism Like most researchers I know, I‚Äôve been politically...","categories": ["squib"],
        "tags": ["academia","socialNLP"],
        "url": "/2019/conversation/",
        "teaser": null
      },{
        "title": "How to teach NLP to non-CS-majors in 2 weeks?",
        "excerpt":"I strongly believe that getting machines to understand natural language, if at all possible, will require much interdisciplinary collaboration. It‚Äôs not clear whether NLP models should be biologically plausible or explicitly encode any linguistic structures ‚Äì but we do know that language is a very complex thing, and no discipline...","categories": ["squib"],
        "tags": ["academia","teaching"],
        "url": "/2019/nlp4linguists/",
        "teaser": null
      },{
        "title": "Peer review in NLP: reject-if-not-SOTA",
        "excerpt":"Everything wrong with reject-if-not-SOTA After each reviewing round for a major conference, #NLProc Twitter erupts with bitter reports of methods rejected for failing to achieve the state-of-the-art status (SOTA). Another @emnlp2019 reviewer&#39;s 3-line review concludes: &quot;The main weakness of the paper is the results do not beat the state of...","categories": ["squib"],
        "tags": ["academia","methodology","peer-review"],
        "url": "/2020/reviewing-models/",
        "teaser": null
      },{
        "title": "Peer review in NLP: resource papers",
        "excerpt":"Dangerous preconceptions about resource papers Most success stories in NLP are about supervised or semi-supervised learning. Fundamentally, that means that our parsers, sentiment classifiers, QA systems and everything else are only as good as the training data, and that fact makes data and model engineering equally important for further progress....","categories": ["squib"],
        "tags": ["academia","methodology","peer-review"],
        "url": "/2020/reviewing-data/",
        "teaser": null
      },{
        "title": "Should the reviewers know who the authors are?",
        "excerpt":"This post is my $0.02 in the ongoing debate about ACL peer review reform. TLDR if you‚Äôve missed that: ACL is discussing the ways to improve peer review, and released short-term and long-term review proposals that generated many lively discussions on Twitter and in ACL 2020. The debate is still...","categories": ["squib"],
        "tags": ["academia","peer-review"],
        "url": "/2020/anonymity/",
        "teaser": null
      },{
        "title": "How to Record a Virtual Conference Talk",
        "excerpt":"Virtual talks have been the bliss and the curse of NLP virtual conferences. Because of the efforts to preserve them and link them up to the paper pages in ACL anthology, they are the bliss for the audience, and greatly improve conference accessibility worldwide. But for the authors they are...","categories": ["howto"],
        "tags": ["academia","productivity"],
        "url": "/2021/recording/",
        "teaser": null
      },{
        "title": "Field Notes on Hybrid Conferences (EMNLP 2021)",
        "excerpt":"This is a quick summary of my field notes on the hybrid conferences from EMNLP2021 üå¥, as an on-site attendee. I was able to attend thanks to WiNLP travel award, for their panel on the role of peer review in diversifying NLP. This was the first ever *ACL hybrid conference,...","categories": ["howto"],
        "tags": ["academia","organization","conference"],
        "url": "/2021/hybrid/",
        "teaser": null
      },{
        "title": "The attribution problem with generative AI",
        "excerpt":"When the discussion about large pre-trained generative models hits the question of ‚Äúwhat about all this work of artists, programmers and writers that is used in commercial products/models without their knowledge or consent?‚Äù, one of the arguments for why this is ok is the comparison of such models to latent...","categories": ["squib"],
        "tags": ["ethics","debate","LLMs"],
        "url": "/2022/attribution/",
        "teaser": null
      },{
        "title": "Closed AI Models Make Bad Baselines",
        "excerpt":"This post was authored by Anna Rogers, with much invaluable help and feedback from Niranjan Balasubramanian, Leon Derczynski, Jesse Dodge, Alexander Koller, Sasha Luccioni, Maarten Sap, Roy Schwartz, Noah A. Smith, Emma Strubell (listed alphabetically) Header image credit: Sasha Luccioni What comes below is an attempt to bring together some...","categories": ["squib"],
        "tags": ["LLMs","ethics","peer-review","academia"],
        "url": "/2023/closed-baselines/",
        "teaser": null
      }]

var store = [{
        "title": "Why blog about NLP in 2019?",
        "excerpt":"When I said I wanted to start a research blog, I got asked why - wasn't it something from the nineties that nobody did anymore? That's actually not an unreasonable question: nobody is even able to keep up with arXiv anymore, why introduce any more sources of long reads? Sure,...","categories": ["squib"],
        "tags": ["academia"],
        "url": "/2019/why-blog/",
        "teaser": null
      },{
        "title": "How the Transformers broke NLP leaderboards",
        "excerpt":"> This post summarizes some of the recent XLNet-prompted discussions on Twitter and offline. Idea credits go to Yoav Goldberg, Sam Bowman, Jason Weston, Alexis Conneau, Ted Pedersen, fellow members of Text Machine Lab, and many others. Any misconfiguration of those ideas is my own. A big reason why NLP...","categories": ["squib"],
        "tags": ["academia","methodology","transformers"],
        "url": "/2019/leaderboards/",
        "teaser": null
      },{
        "title": "On word analogies and negative results in NLP",
        "excerpt":"In real world, fake news spread faster than facts. People's attention is caught by sensational, exaggerated, clickbait-y messages like \"5.23 million more immigrants are moving to the UK\". Any subsequent fact-checking messages look less sensational and they will not reach as many people. Once the damage is done, it's done....","categories": ["squib"],
        "tags": ["methodology","negative-results","review"],
        "url": "/2019/analogies/",
        "teaser": null
      },{
        "title": "Talking to people outside your echo chamber: SocNLP challenges",
        "excerpt":"> This blog is NOT political, even though the story below will show some of my political views. I'm sharing it because it highlights a burning issue in computational social science that is getting nowhere near enough attention. Reader beware. ## Academics and Populism Like most researchers I know, I've...","categories": ["squib"],
        "tags": ["society"],
        "url": "/2019/conversation/",
        "teaser": null
      },{
        "title": "How to teach NLP to non-CS-majors in 2 weeks?",
        "excerpt":"I strongly believe that getting machines to understand natural language, if at all possible, will require much interdisciplinary collaboration. It's not clear whether NLP models should be biologically plausible or explicitly encode any linguistic structures -- but we do know that language is a very complex thing, and no discipline...","categories": ["squib"],
        "tags": ["teaching"],
        "url": "/2019/nlp4linguists/",
        "teaser": null
      },{
        "title": "[Text Machine Lab] BERT Busters: Outlier Dimensions that Disrupt Transformers",
        "excerpt":"This is a post I wrote during my time in Text Machine Lab: [https://text-machine-lab.github.io/blog/2020/bert-secrets/](https://text-machine-lab.github.io/blog/2020/bert-secrets/). It reports on an influential paper on the analysis of self-attention mechanism in BERT, which by 2023 had over 500 citations: > Olga Kovaleva, Alexey Romanov, Anna Rogers, and Anna Rumshisky. 2019. Revealing the Dark Secrets...","categories": ["paper"],
        "tags": ["transformers"],
        "url": "/2020/dark-secrets/",
        "teaser": null
      },{
        "title": "[Text Machine Lab] Question Answering for Artificial Intelligence (QuAIL)",
        "excerpt":"This is a post I wrote during my time in Text Machine Lab: [https://text-machine-lab.github.io/blog/2020/quail/](https://text-machine-lab.github.io/blog/2020/quail/). It presents an English resource for machine reading comprehension, balanced across 4 domains and 9 question types - and our experience of getting the crowdworkers to generate diverse types of data. There are also some follow-up...","categories": ["paper"],
        "tags": ["machine-reasoning"],
        "url": "/2020/quail/",
        "teaser": null
      },{
        "title": "Peer review in NLP: reject-if-not-SOTA",
        "excerpt":"## Everything wrong with reject-if-not-SOTA After each reviewing round for a major conference, #NLProc Twitter erupts with bitter reports of methods rejected for failing to achieve the state-of-the-art status (SOTA). Another @emnlp2019 reviewer&#39;s 3-line review concludes: &quot;The main weakness of the paper is the results do not beat the state...","categories": ["squib"],
        "tags": ["methodology","peer-review"],
        "url": "/2020/reviewing-models/",
        "teaser": null
      },{
        "title": "Peer review in NLP: resource papers",
        "excerpt":"## Dangerous preconceptions about resource papers Most success stories in NLP are about supervised or semi-supervised learning. Fundamentally, that means that our parsers, sentiment classifiers, QA systems and everything else are only as good as the training data, and that fact makes data and model engineering equally important for further...","categories": ["squib"],
        "tags": ["methodology","peer-review"],
        "url": "/2020/reviewing-data/",
        "teaser": null
      },{
        "title": "Should the reviewers know who the authors are?",
        "excerpt":"> This post is my $0.02 in the ongoing debate about ACL peer review reform. TLDR if you've missed that: ACL is discussing the ways to improve peer review, and released [short-term](https://www.aclweb.org/adminwiki/index.php?title=Short-Term_Reform_Proposals_for_ACL_Reviewing) and [long-term](https://www.aclweb.org/adminwiki/index.php?title=ACL_Rolling_Review_Proposal) review proposals that generated many lively discussions on Twitter and in ACL 2020. The debate is...","categories": ["squib"],
        "tags": ["academia","peer-review"],
        "url": "/2020/anonymity/",
        "teaser": null
      },{
        "title": "[The Gradient] How Can We Improve Peer Review in NLP?",
        "excerpt":"This is a post I wrote for The Gradient: [https://thegradient.pub/how-can-we-improve-peer-review-in-nlp/](https://thegradient.pub/how-can-we-improve-peer-review-in-nlp/). It reports on a position paper that discusses the heuristics used by reviewers in NLP conferences, and what are the feasible goals for the peer review process. > Anna Rogers and Isabelle Augenstein. 2020. What Can We Do to Improve...","categories": ["paper"],
        "tags": ["peer-review"],
        "url": "/2020/improving-review/",
        "teaser": null
      },{
        "title": "[The Gradient] When BERT Plays The Lottery, All Tickets Are Winning",
        "excerpt":"This is a post I wrote for The Gradient: [https://thegradient.pub/when-bert-plays-the-lottery-all-tickets-are-winning/](https://thegradient.pub/when-bert-plays-the-lottery-all-tickets-are-winning/). It reports on our investigation of the lottery ticket hypothesis for pre-trained Transformers, in particular BERT: > Sai Prasanna, Anna Rogers, and Anna Rumshisky. 2020. When BERT Plays the Lottery, All Tickets Are Winning. In Proceedings of the 2020 Conference...","categories": ["paper"],
        "tags": ["transformers"],
        "url": "/2020/lottery/",
        "teaser": null
      },{
        "title": "How to Record a Virtual Conference Talk",
        "excerpt":"Virtual talks have been the bliss and the curse of NLP virtual conferences. Because of the efforts to preserve them and link them up to the paper pages in ACL anthology, they are the bliss for the audience, and greatly improve conference accessibility worldwide. But for the authors they are...","categories": ["howto"],
        "tags": ["productivity"],
        "url": "/2021/recording/",
        "teaser": null
      },{
        "title": "[Text Machine Lab] BERT Busters: Outlier Dimensions that Disrupt Transformers",
        "excerpt":"This is a post I wrote during my time in Text Machine Lab: [https://text-machine-lab.github.io/blog/2021/busters/](https://text-machine-lab.github.io/blog/2021/busters/). It reports on one of the first studies on the phenomenon of outlier dimensions in Transformer-based language models: > Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers, and Anna Rumshisky. 2021. BERT Busters: Outlier Dimensions that Disrupt Transformers....","categories": ["paper"],
        "tags": ["transformers"],
        "url": "/2021/bert-busters/",
        "teaser": null
      },{
        "title": "Field Notes on Hybrid Conferences (EMNLP 2021)",
        "excerpt":"This is a quick summary of my field notes on the hybrid conferences from EMNLP2021 ðŸŒ´, as an on-site attendee. I was able to attend thanks to [WiNLP](http://www.winlp.org/winlp-emnlp-2021/) travel award, for their panel on the role of peer review in diversifying NLP. _This was the first ever *ACL hybrid conference,...","categories": ["howto"],
        "tags": ["conferences"],
        "url": "/2021/hybrid/",
        "teaser": null
      },{
        "title": "The attribution problem with generative AI",
        "excerpt":"When the discussion about large pre-trained generative models hits the question of \"what about all this work of artists, programmers and writers that is used in commercial products/models without their knowledge or consent?\", one of the arguments for why this is ok is the comparison of such models to latent...","categories": ["squib"],
        "tags": ["ethics","debate","LLMs"],
        "url": "/2022/attribution/",
        "teaser": null
      },{
        "title": "[ACL 2023] Generative AI Policy",
        "excerpt":"This blog post (on the conference website) summarized our approach to the use of generative AI in ACL conference submissions and reviewing: [https://2023.aclweb.org/blog/reviewer-assignment/](https://2023.aclweb.org/blog/reviewer-assignment/). I was its lead author.","categories": ["squib"],
        "tags": ["peer-review","academia","conferences"],
        "url": "/2023/ai-policy/",
        "teaser": null
      },{
        "title": "[ACL 2023] Paper-Reviewer Matching",
        "excerpt":"As a program chair of ACL'23, I was the lead author for this blog post on the conference website that summarized our approach to peer-review matching: [https://2023.aclweb.org/blog/reviewer-assignment/](https://2023.aclweb.org/blog/reviewer-assignment/) I was also the lead developer of this approach to matching. Post-mortem analysis of how it worked is available in this report: >...","categories": ["squib"],
        "tags": ["peer-review","conferences"],
        "url": "/2023/reviewer-matching/",
        "teaser": null
      },{
        "title": "Closed AI Models Make Bad Baselines",
        "excerpt":"> *This post was authored by Anna Rogers, with much invaluable help and feedback from Niranjan Balasubramanian, Leon Derczynski, Jesse Dodge, Alexander Koller, Sasha Luccioni, Maarten Sap, Roy Schwartz, Noah A. Smith, Emma Strubell (listed alphabetically)* > Header image credit: Sasha Luccioni What comes below is an attempt to bring...","categories": ["squib"],
        "tags": ["LLMs","ethics","peer-review","academia","methodology"],
        "url": "/2023/closed-baselines/",
        "teaser": null
      },{
        "title": "[ACL 2023] Peer Review Report",
        "excerpt":"This post (at ACL conference website) summarizes the analysis of ACL'23 peer review process: [https://2023.aclweb.org/blog/review-report/](https://2023.aclweb.org/blog/review-report/). The full analysis is available in this huge report that is up on ACL Anthology: > Anna Rogers, Marzena Karpinska, Jordan Boyd-Graber, and Naoaki Okazaki. 2023. Program Chairsâ€™ Report on Peer Review at ACL 2023....","categories": ["squib"],
        "tags": ["peer-review","conferences"],
        "url": "/2023/peer-review-report/",
        "teaser": null
      },{
        "title": "I am joining ACL Rolling Review",
        "excerpt":"It's official: I joined the [ACL Rolling Review team](https://aclrollingreview.org/people) as an editor-in-chief, and I'd like to share some brief thoughts on this. When ACL Rolling Review was first launched, I wasn't its biggest fan. The core motivation seemed to be that it would reduce the reviewer workload, and I am...","categories": ["squib"],
        "tags": ["peer-review","academia","ethics"],
        "url": "/2024/joining-arr/",
        "teaser": null
      }]
